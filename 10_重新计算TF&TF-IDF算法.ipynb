{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readnegfile(i):\n",
    "    text=open('neg.'+str(i)+'.txt',encoding = 'utf-8').read()\n",
    "    return text\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    list_text=[]\n",
    "    for i in range(11):\n",
    "        list_text.append(readnegfile(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_text = [i.replace('\\n','') for i in list_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['标准间太差 房间还不如3星的 而且设施非常陈旧.建议酒店把老的标准间从新改善.',\n",
       " '服务态度极其差，前台接待好象没有受过培训，连基本的礼貌都不懂，竟然同时接待几个客人；大堂副理更差，跟客人辩解个没完，要总经理的电话投诉竟然都不敢给。要是没有作什么亏心事情，根本不用这么怕。',\n",
       " '过了好久才想起来评价，记得离火车站超级近，不过方便的同时必然会觉得比较吵。韩日旅游团住这里的很多，前台服务冷淡。两个人住标准间，只给一张房卡，还很挑衅的看我。气的没心情。宾馆反馈 2008年7月17日 ： 酒店针对客人提出的问题，现已认真整改，希望每一位入住渤海明珠酒店的您都能高兴入住，满意而归。',\n",
       " '预订标准间：拐角房间（为什么携程订的都是拐角间），房间很小，隔音超差，房间非常冷，空调几乎不好用，卫生间更冷，几乎没法淋浴！三个字”不满意”！',\n",
       " '过了好久才想起来评价，记得离火车站超级近，不过方便的同时必然会觉得比较吵。韩日旅游团住这里的很多，前台服务冷淡。两个人住标准间，只给一张房卡，还很挑衅的看我。气的没心情。宾馆反馈 2008年7月17日 ： 酒店针对客人提出的问题，现已认真整改，希望每一位入住渤海明珠酒店的您都能高兴入住，满意而归。',\n",
       " '预订标准间：拐角房间（为什么携程订的都是拐角间），房间很小，隔音超差，房间非常冷，空调几乎不好用，卫生间更冷，几乎没法淋浴！三个字”不满意”！',\n",
       " '27日入住正赶上附近施工，第一印象不好，29日离开时，大厅有钢琴小提琴的表演。订房时（大/双）没得挑，入住时被告知是两间豪标双人间，其实想要一大一双。总之不尽如人意。',\n",
       " '27日入住正赶上附近施工，第一印象不好，29日离开时，大厅有钢琴小提琴的表演。订房时（大/双）没得挑，入住时被告知是两间豪标双人间，其实想要一大一双。总之不尽如人意。',\n",
       " '郁闷!!!气愤!!不明白光纤竟然比上海锦江之星的网速还慢,想要晚上网速快千万别去这家!!!因网上介绍的是光纤网络,所以才去它家.结果登个QQ也要好久,网速跟爬似的.和国外朋友约好上网,结果卡的不行,连上海的朋友也说听我说话有一句没一句的.我在大连和人合租滴房,因怕晚上和国外朋友聊天影响同租人休息,才去了酒店,结果出了钱还没聊成.打电话去前台,说是电脑部下班了,让电工来看下,后来让我去隔壁房间试下,结果一样慢.酒店不是应该24小时服务的吗?',\n",
       " '房间很小，与行政间的名字不符。另外这家酒店的按摩可千万不能叫，超级黑！结帐时居然会有打手上来，请大家注意！决不会再入住此酒店。',\n",
       " '地理位置还不错，到哪里都比较方便，但是服务不象是豪生集团管理的，比较差。下午睡了一觉并洗了一个澡，本来想让酒店再来打扫一下，所以，打开了，请打扫的服务灯，可是到晚上回酒店，发现打扫得服务灯被关掉了，而房间还是没有打扫过。']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# withoutstop在6中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readnegfile_withoutstop(i):\n",
    "    text=open('neg.'+str(i)+'.withoutstop.txt',encoding = 'utf-8').read()\n",
    "    return text\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    list_text_withoutstop=[]\n",
    "    for i in range(11):\n",
    "        list_text_withoutstop.append(readnegfile_withoutstop(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_text_withoutstop = [i.strip() for i in list_text_withoutstop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['标准间 太 差   房间 星   设施 陈旧 建议 酒店 标准间 新 改善',\n",
       " '服务态度 差 前台 接待 好象 受过 培训 礼貌 懂 接待 几个 客人 大堂 副理 差 客人 辩解 没完 总经理 电话 投诉 不敢 作 亏心事 情 根本 不用',\n",
       " '好久 想 评价 记得 火车站 超级 方便 必然 觉得 比较 吵 韩日 旅游团 住 前台 服务 冷淡 两个 人住 标准间 只 一张 房卡 挑衅 气 心情 宾馆 反馈   2008 年 月 17 日     酒店 针对 客人 提出 问题 现已 认真 整改 希望 一位 入住 渤海 明珠 酒店 高兴 入住 满意',\n",
       " '预订 标准间 拐角 房间 携程 订 拐角 间 房间 很小 隔音 超差 房间 冷 空调 不好 卫生间 冷 没法 淋浴 三个 字 满意',\n",
       " '好久 想 评价 记得 火车站 超级 方便 必然 觉得 比较 吵 韩日 旅游团 住 前台 服务 冷淡 两个 人住 标准间 只 一张 房卡 挑衅 气 心情 宾馆 反馈   2008 年 月 17 日     酒店 针对 客人 提出 问题 现已 认真 整改 希望 一位 入住 渤海 明珠 酒店 高兴 入住 满意',\n",
       " '预订 标准间 拐角 房间 携程 订 拐角 间 房间 很小 隔音 超差 房间 冷 空调 不好 卫生间 冷 没法 淋浴 三个 字 满意',\n",
       " '27 日 入住 正赶上 附近 施工 第一印象 不好 29 日 离开 时 大厅 钢琴 小提琴 表演 订房 时 双 没得 挑 入住 时 告知 两间 豪标 双人间 想要 一大 一双',\n",
       " '27 日 入住 正赶上 附近 施工 第一印象 不好 29 日 离开 时 大厅 钢琴 小提琴 表演 订房 时 双 没得 挑 入住 时 告知 两间 豪标 双人间 想要 一大 一双',\n",
       " '郁闷 气愤 明白 光纤 上海 锦江 之星 网速 还慢 想要 晚上 网速 千万别 这家 网上 介绍 光纤网络 家 登个 QQ 好久 网速 爬 国外 朋友 约 好 上网 卡 不行 上海 朋友 说 听 说话 一句 一句 大连 人 合租 滴房 因怕 晚上 国外 朋友 聊天 影响 同租 人 休息 酒店 钱 没聊 成 打电话 前台 说 电脑部 下班 电工 下 隔壁 房间 试下 慢 酒店 应该 24 小时 服务',\n",
       " '房间 很小 行政 间 名字 不符 这家 酒店 按摩 超级 黑 结帐 时 打手 请 注意 决不会 再 入住 酒店',\n",
       " '地理位置 不错 比较 方便 服务 象是 豪生 集团 管理 比较 差 下午 睡 一觉 洗 一个 澡 本来 想 酒店 再 打扫 一下 打开 请 打扫 服务 灯 晚上 回 酒店 发现 打扫 服务 灯 关掉 房间 打扫']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_text_withoutstop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================result====================\n",
      "\n",
      "docs:\n",
      " ['标准间 太 差   房间 星   设施 陈旧 建议 酒店 标准间 新 改善'\n",
      " '服务态度 差 前台 接待 好象 受过 培训 礼貌 懂 接待 几个 客人 大堂 副理 差 客人 辩解 没完 总经理 电话 投诉 不敢 作 亏心事 情 根本 不用'\n",
      " '好久 想 评价 记得 火车站 超级 方便 必然 觉得 比较 吵 韩日 旅游团 住 前台 服务 冷淡 两个 人住 标准间 只 一张 房卡 挑衅 气 心情 宾馆 反馈   2008 年 月 17 日     酒店 针对 客人 提出 问题 现已 认真 整改 希望 一位 入住 渤海 明珠 酒店 高兴 入住 满意'\n",
      " '预订 标准间 拐角 房间 携程 订 拐角 间 房间 很小 隔音 超差 房间 冷 空调 不好 卫生间 冷 没法 淋浴 三个 字 满意'\n",
      " '好久 想 评价 记得 火车站 超级 方便 必然 觉得 比较 吵 韩日 旅游团 住 前台 服务 冷淡 两个 人住 标准间 只 一张 房卡 挑衅 气 心情 宾馆 反馈   2008 年 月 17 日     酒店 针对 客人 提出 问题 现已 认真 整改 希望 一位 入住 渤海 明珠 酒店 高兴 入住 满意'\n",
      " '预订 标准间 拐角 房间 携程 订 拐角 间 房间 很小 隔音 超差 房间 冷 空调 不好 卫生间 冷 没法 淋浴 三个 字 满意'\n",
      " '27 日 入住 正赶上 附近 施工 第一印象 不好 29 日 离开 时 大厅 钢琴 小提琴 表演 订房 时 双 没得 挑 入住 时 告知 两间 豪标 双人间 想要 一大 一双'\n",
      " '27 日 入住 正赶上 附近 施工 第一印象 不好 29 日 离开 时 大厅 钢琴 小提琴 表演 订房 时 双 没得 挑 入住 时 告知 两间 豪标 双人间 想要 一大 一双'\n",
      " '郁闷 气愤 明白 光纤 上海 锦江 之星 网速 还慢 想要 晚上 网速 千万别 这家 网上 介绍 光纤网络 家 登个 QQ 好久 网速 爬 国外 朋友 约 好 上网 卡 不行 上海 朋友 说 听 说话 一句 一句 大连 人 合租 滴房 因怕 晚上 国外 朋友 聊天 影响 同租 人 休息 酒店 钱 没聊 成 打电话 前台 说 电脑部 下班 电工 下 隔壁 房间 试下 慢 酒店 应该 24 小时 服务'\n",
      " '房间 很小 行政 间 名字 不符 这家 酒店 按摩 超级 黑 结帐 时 打手 请 注意 决不会 再 入住 酒店'\n",
      " '地理位置 不错 比较 方便 服务 象是 豪生 集团 管理 比较 差 下午 睡 一觉 洗 一个 澡 本来 想 酒店 再 打扫 一下 打开 请 打扫 服务 灯 晚上 回 酒店 发现 打扫 服务 灯 关掉 房间 打扫']\n",
      "\n",
      "words:\n",
      " ['标准间' '房间' '设施' '陈旧' '建议' '酒店' '改善' '服务态度' '前台' '接待' '好象' '受过' '培训' '礼貌'\n",
      " '几个' '客人' '大堂' '副理' '辩解' '没完' '总经理' '电话' '投诉' '不敢' '亏心事' '根本' '不用' '好久'\n",
      " '评价' '记得' '火车站' '超级' '方便' '必然' '觉得' '比较' '韩日' '旅游团' '服务' '冷淡' '两个' '人住'\n",
      " '一张' '房卡' '挑衅' '心情' '宾馆' '反馈' '2008' '17' '针对' '提出' '问题' '现已' '认真' '整改'\n",
      " '希望' '一位' '入住' '渤海' '明珠' '高兴' '满意' '预订' '拐角' '携程' '很小' '隔音' '超差' '空调'\n",
      " '不好' '卫生间' '没法' '淋浴' '三个' '27' '正赶上' '附近' '施工' '第一印象' '29' '离开' '大厅' '钢琴'\n",
      " '小提琴' '表演' '订房' '没得' '告知' '两间' '豪标' '双人间' '想要' '一大' '一双' '郁闷' '气愤' '明白'\n",
      " '光纤' '上海' '锦江' '之星' '网速' '还慢' '晚上' '千万别' '这家' '网上' '介绍' '光纤网络' '登个' 'qq'\n",
      " '国外' '朋友' '上网' '不行' '说话' '一句' '大连' '合租' '滴房' '因怕' '聊天' '影响' '同租' '休息'\n",
      " '没聊' '打电话' '电脑部' '下班' '电工' '隔壁' '试下' '应该' '24' '小时' '行政' '名字' '不符' '按摩'\n",
      " '结帐' '打手' '注意' '决不会' '地理位置' '不错' '象是' '豪生' '集团' '管理' '下午' '一觉' '一个' '本来'\n",
      " '打扫' '一下' '打开' '发现' '关掉']\n",
      "\n",
      "oneHots:\n",
      " [[1 0 1 ... 0 0 0]\n",
      " [1 0 0 ... 1 1 1]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]]\n",
      "\n",
      "CF:\n",
      " [[2 1 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 1 0 ... 1 1 1]]\n",
      "\n",
      "TF:\n",
      " [[0.25       0.125      0.125      ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.02380952 0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.01754386 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.06666667 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.03571429 0.         ... 0.03571429 0.03571429 0.03571429]]\n",
      "11\n",
      "159\n",
      "\n",
      "DF:\n",
      " [5 6 1 1 1 6 1 1 4 1 1 1 1 1 1 3 1 1 1 1 1 2 1 1 1 1 1 3 2 2 2 3 3 2 2 3 2\n",
      " 2 5 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 5 2 2 2 4 2 2 2 3 2 2 2 4 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      "IDF:\n",
      " [0.26324143 0.19629465 0.74036269 0.74036269 0.74036269 0.19629465\n",
      " 0.74036269 0.74036269 0.34242268 0.74036269 0.74036269 0.74036269\n",
      " 0.74036269 0.74036269 0.74036269 0.43933269 0.74036269 0.74036269\n",
      " 0.74036269 0.74036269 0.74036269 0.56427143 0.74036269 0.74036269\n",
      " 0.74036269 0.74036269 0.74036269 0.43933269 0.56427143 0.56427143\n",
      " 0.56427143 0.43933269 0.43933269 0.56427143 0.56427143 0.43933269\n",
      " 0.56427143 0.56427143 0.26324143 0.56427143 0.56427143 0.56427143\n",
      " 0.56427143 0.56427143 0.56427143 0.56427143 0.56427143 0.56427143\n",
      " 0.56427143 0.56427143 0.56427143 0.56427143 0.56427143 0.56427143\n",
      " 0.56427143 0.56427143 0.56427143 0.56427143 0.26324143 0.56427143\n",
      " 0.56427143 0.56427143 0.34242268 0.56427143 0.56427143 0.56427143\n",
      " 0.43933269 0.56427143 0.56427143 0.56427143 0.34242268 0.56427143\n",
      " 0.56427143 0.56427143 0.56427143 0.56427143 0.56427143 0.56427143\n",
      " 0.56427143 0.56427143 0.56427143 0.56427143 0.56427143 0.56427143\n",
      " 0.56427143 0.56427143 0.56427143 0.56427143 0.56427143 0.56427143\n",
      " 0.56427143 0.56427143 0.43933269 0.56427143 0.56427143 0.74036269\n",
      " 0.74036269 0.74036269 0.74036269 0.74036269 0.74036269 0.74036269\n",
      " 0.74036269 0.74036269 0.56427143 0.74036269 0.56427143 0.74036269\n",
      " 0.74036269 0.74036269 0.74036269 1.04139269 0.74036269 0.74036269\n",
      " 0.74036269 0.74036269 0.74036269 0.74036269 0.74036269 0.74036269\n",
      " 0.74036269 0.74036269 0.74036269 0.74036269 0.74036269 0.74036269\n",
      " 0.74036269 0.74036269 0.74036269 0.74036269 0.74036269 0.74036269\n",
      " 0.74036269 0.74036269 0.74036269 0.74036269 0.74036269 0.74036269\n",
      " 0.74036269 0.74036269 0.74036269 0.74036269 0.74036269 0.74036269\n",
      " 0.74036269 0.74036269 0.74036269 0.74036269 0.74036269 0.74036269\n",
      " 0.74036269 0.74036269 0.74036269 0.74036269 0.74036269 0.74036269\n",
      " 0.74036269 0.74036269 0.74036269]\n",
      "\n",
      "TF-IDF:\n",
      " [[0.06581036 0.02453683 0.09254534 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.00626765 0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.00344377 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.01308631 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.00701052 0.         ... 0.02644152 0.02644152 0.02644152]]\n",
      "11\n",
      "159\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "def sklearn_tfidf():\n",
    "    vectorizer = CountVectorizer() #将文本中的词语转换为词频矩阵\n",
    "    X = vectorizer.fit_transform(list_text_withoutstop) #计算个词语出现的次数\n",
    "    \n",
    "    transformer = TfidfTransformer()\n",
    "    tfidf = transformer.fit_transform(X) #将词频矩阵X统计成TF-IDF\n",
    "    print (tfidf.toarray())\n",
    "\t\n",
    "def tfidf_alg():\n",
    "    # 创建transform\n",
    "    vectorizer = CountVectorizer()\n",
    "    # 分词并建立词汇表\n",
    "    vectorizer.fit(list_text_withoutstop)\n",
    "    # 结果输出\n",
    "    cv_dict = vectorizer.vocabulary_\n",
    "    \n",
    "    docs = np.array(list_text_withoutstop)\n",
    "    words = np.array(list(cv_dict.keys()))\n",
    "\t# calc of way1，词在文档中出现的个数\n",
    "    cfs = []\n",
    "    for e in docs:\n",
    "        cf = [e.count(word) for word in words]\n",
    "        cfs.append(cf)\n",
    "\t#print ('cfs way1:\\n', np.array(cfs))\n",
    "\t\n",
    "\t# calc of way2，词在文档中出现的个数\n",
    "    cfs = []\n",
    "    cfs.extend([e.count(word) for word in words] for e in docs)\n",
    "    cfs = np.array(cfs)\n",
    "\t#print ('cfs ways:\\n', cfs)\n",
    "\t\n",
    "\t# calc tf way1，词在文档中的频率\n",
    "    tfs = []\n",
    "    tfs.extend(e/(np.sum(e)) for e in cfs) #不能使用append()\n",
    "\t#print ('tfs:\\n',np.array(tfs))\n",
    "\t\n",
    "\t# calc tf way2,词在文档中的频率\n",
    "    tfs = []\n",
    "    tfs.extend(e/(np.sum(e)) for e in cfs) #不能使用append()\n",
    "\t\n",
    "\t# calc df way1,包含词的文档个数\n",
    "    dfs = list(np.zeros(words.size, dtype = int))\n",
    "    for i in range(words.size):\n",
    "        for doc in docs:\n",
    "            if doc.find(words[i])!= -1:\n",
    "                dfs[i] += 1\n",
    "\t#print ('calc df way1:',dfs)\n",
    "\t\n",
    "\t# calc df way2，包含词的文档个数\n",
    "    dfs = []\n",
    "    for i in range(words.size):\n",
    "        oneHot = [(doc.find(words[i])!=-1 and 1 or 0) for doc in docs]\n",
    "        dfs.append(oneHot.count(1))\n",
    "\t\t#print ('word',words[i],'df:',oneHot.count(1))\n",
    "\t#print ('calc df way2:',dfs)\n",
    "\t\n",
    "\t# calc df way3,包含文辞的文档个数\n",
    "    dfs, oneHots = [],[]\n",
    "    for word in words:\n",
    "        oneHots.append([(e.find(word)!= -1 and 1 or 0) for e in docs])\n",
    "    dfs.extend(e.count(1) for e in oneHots)\n",
    "\t#print ('calc oneHots way3:', np.array(oneHots))\n",
    "\t#print ('calc df way3:',dfs)\n",
    "\t\n",
    "\t# calc df way4,包含的文档个数\n",
    "    dfs = []\n",
    "    oneHots = [[doc.find(word)!= -1 and 1 or 0 for doc in docs] for word in words]\n",
    "    dfs.extend(e.count(1) for e in oneHots)\n",
    "\t#print ('calc oneHots way4:',np.array(oneHots))\n",
    "\t#dfs = np.reshape(dfs, (np.shape(dfs)[0],1)) #列向量1×n  \n",
    "    #print('calc df way4:', dfs)  \n",
    "      \n",
    "    #calc idf, 计算每个词的idf(逆向文件频率inverse document frequency)  \n",
    "    #log10(N/(1+DF)) \n",
    "    N = np.shape(docs)[0]\n",
    "    idfs = [(np.log10(N*1.0/(1+e))) for e in dfs] #f(e) = np.log10(N*1.0/(1+e))\n",
    "\t#print ('idfs:',np.array(idfs))\n",
    "\t\n",
    "\t#calc tf-idf,计算term frequency - inverse document frequency\n",
    "    tfidfs = []\n",
    "    for i in range(np.shape(docs)[0]):\n",
    "        word_tfidf = np.multiply(tfs[i], idfs)\n",
    "        tfidfs.append(word_tfidf)\n",
    "\t\t#print('word_tfidf:',word_tfidf)\n",
    "\t#print('calc tfidfs:\\n', np.array(tfidfs))\n",
    "\t\n",
    "    print('=====================result====================')\n",
    "    print('\\ndocs:\\n',np.array(docs))\n",
    "    print('\\nwords:\\n',np.array(words))\n",
    "    print('\\noneHots:\\n',np.array(oneHots))\n",
    "    print('\\nCF:\\n',np.array(cfs))\n",
    "    print('\\nTF:\\n',np.array(tfs))\n",
    "    print(len(np.array(tfs)))\n",
    "    print(len(np.array(tfs)[0]))\n",
    "    print('\\nDF:\\n',np.array(dfs))\n",
    "    print('\\nIDF:\\n',np.array(idfs))\n",
    "    print('\\nTF-IDF:\\n',np.array(tfidfs))\n",
    "    print(len(np.array(tfidfs)))\n",
    "    print(len(np.array(tfidfs)[0]))\n",
    "    \n",
    "    print('=================================================')\n",
    "    return\n",
    "\t\n",
    "if __name__ == '__main__':\n",
    "\ttfidf_alg()\n",
    "\t# sklearn_tfidf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
